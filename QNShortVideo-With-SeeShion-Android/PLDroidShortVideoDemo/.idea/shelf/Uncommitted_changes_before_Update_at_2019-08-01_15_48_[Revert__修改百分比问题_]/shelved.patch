Index: app/build.gradle
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>apply plugin: 'com.android.application'\n\nrepositories {\n    flatDir {\n        dirs 'libs'\n    }\n}\n\nandroid {\n    compileSdkVersion 25\n    buildToolsVersion \"25.0.2\"\n\n    defaultConfig {\n        applicationId \"com.qiniu.pili.droid.shortvideo.demo\"\n        minSdkVersion 18\n        targetSdkVersion 25\n        versionCode 26\n        versionName \"2.2.0\"\n        multiDexEnabled true\n        buildConfigField \"long\", \"BUILD_TIMESTAMP\", System.currentTimeMillis() + \"L\"\n        ndk {\n            abiFilters 'armeabi-v7a'\n        }\n    }\n    buildTypes {\n        release {\n            minifyEnabled false\n            proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro'\n        }\n    }\n}\n\ndependencies {\n    compile 'com.qiniu:qiniu-android-sdk:7.3.11'\n    compile files('libs/pldroid-shortvideo-2.2.0.jar')\n    compile files('libs/pldroid-player-2.1.8.jar')\n    compile files('libs/EasyAR.jar')\n    compile files('libs/EasyAR3D.jar')\n\n    compile 'com.android.support:multidex:1.0.1'\n    compile 'pl.droidsonroids.gif:android-gif-drawable:1.2.7'\n    compile 'com.android.support:recyclerview-v7:25.3.1'\n    compile 'com.android.support:appcompat-v7:25.3.1'\n    compile 'com.android.support:design:25.3.1'\n    compile 'com.android.support.constraint:constraint-layout:1.0.1'\n\n    compile files('libs/universal-image-loader-1.9.4.jar')\n    compile 'com.h6ah4i.android.widget.advrecyclerview:advrecyclerview:0.10.6'\n    compile 'com.github.bumptech.glide:glide:3.7.0'\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/build.gradle	(date 1564645694000)
+++ app/build.gradle	(date 1564642952000)
@@ -31,11 +31,11 @@
 }
 
 dependencies {
-    compile 'com.qiniu:qiniu-android-sdk:7.3.11'
-    compile files('libs/pldroid-shortvideo-2.2.0.jar')
-    compile files('libs/pldroid-player-2.1.8.jar')
-    compile files('libs/EasyAR.jar')
-    compile files('libs/EasyAR3D.jar')
+    implementation 'com.qiniu:qiniu-android-sdk:7.3.11'
+    implementation files('libs/pldroid-shortvideo-2.2.0.jar')
+    implementation files('libs/pldroid-player-2.1.8.jar')
+    implementation files('libs/EasyAR.jar')
+    implementation files('libs/EasyAR3D.jar')
 
     compile 'com.android.support:multidex:1.0.1'
     compile 'pl.droidsonroids.gif:android-gif-drawable:1.2.7'
Index: ../PLDroidShortVideo/library/src/main/java/com/qiniu/pili/droid/shortvideo/core/ShortAudioRecorderCore.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package com.qiniu.pili.droid.shortvideo.core;\n\nimport android.content.Context;\nimport android.content.res.AssetFileDescriptor;\nimport android.media.MediaCodec;\nimport android.media.MediaExtractor;\nimport android.media.MediaFormat;\nimport android.media.MediaPlayer;\nimport android.view.Surface;\n\nimport com.qiniu.pili.droid.shortvideo.PLAudioEncodeSetting;\nimport com.qiniu.pili.droid.shortvideo.PLAudioFrameListener;\nimport com.qiniu.pili.droid.shortvideo.PLErrorCode;\nimport com.qiniu.pili.droid.shortvideo.PLMicrophoneSetting;\nimport com.qiniu.pili.droid.shortvideo.PLRecordSetting;\nimport com.qiniu.pili.droid.shortvideo.PLRecordStateListener;\nimport com.qiniu.pili.droid.shortvideo.PLVideoSaveListener;\nimport com.qiniu.pili.droid.shortvideo.capture.microphone.AudioManager;\nimport com.qiniu.pili.droid.shortvideo.encode.EncoderBase;\nimport com.qiniu.pili.droid.shortvideo.encode.HWAudioEncoder;\nimport com.qiniu.pili.droid.shortvideo.encode.HWEncoderBase;\nimport com.qiniu.pili.droid.shortvideo.encode.SWAudioEncoder;\nimport com.qiniu.pili.droid.shortvideo.parser.RawFrameExtractor;\nimport com.qiniu.pili.droid.shortvideo.transcoder.audio.AudioResampler;\nimport com.qiniu.pili.droid.shortvideo.utils.Draft;\nimport com.qiniu.pili.droid.shortvideo.utils.Logger;\n\nimport java.io.IOException;\nimport java.nio.ByteBuffer;\nimport java.util.Stack;\n\nimport static com.qiniu.pili.droid.shortvideo.core.AuthModel.Feature.record_audio_mix;\nimport static com.qiniu.pili.droid.shortvideo.core.AuthModel.Feature.record_mute;\nimport static com.qiniu.pili.droid.shortvideo.utils.MediaUtils.createMediaExtractor;\nimport static com.qiniu.pili.droid.shortvideo.utils.MediaUtils.selectAudioTrackAndGetFormat;\n\nimport com.qiniu.pili.droid.shortvideo.core.AuthModel.Feature;\n\npublic class ShortAudioRecorderCore implements\n        PLAudioFrameListener,\n        SectionManager.OnSectionStateChangedListener {\n    private static final String TAG = \"ShortAudioRecorderCore\";\n\n    protected volatile boolean mSourcesReadying;\n\n    protected volatile boolean mAudioSourceReady;\n\n    protected volatile boolean mEncodersReadying;\n\n    protected volatile boolean mAudioEncoderReady;\n    protected volatile boolean mAudioFormatReady;\n\n    protected volatile boolean mSectionBegan;\n\n    protected Context mContext;\n    protected PLRecordSetting mRecordSetting;\n    protected PLMicrophoneSetting mMicrophoneSetting;\n    protected PLAudioEncodeSetting mAudioEncodeSetting;\n\n    protected AudioManager mAudioManager;\n    private EncoderBase mAudioEncoder;\n    protected SectionManager mSectionManager;\n\n    private PLAudioFrameListener mAudioFrameListener;\n    protected PLRecordStateListener mRecordStateListener;\n\n    protected QosManager mQosManager;\n\n    private volatile boolean mConcatSectionsOnStop;\n    private volatile boolean mIsMusicPlayerPrepared;\n\n    private PLVideoSaveListener mVideoSaveListener;\n\n    protected double mRecordSpeed = 1.0;\n    private boolean mMaxDurationCalibrated = false;\n\n    private AudioSpeedAdjustor mAudioSpeedAdjustor = new AudioSpeedAdjustor();\n\n    private MediaPlayer mMusicPlayer;\n    private Stack<Integer> mStartTimeOfSections;\n    private Stack<Object> mMusicPaths;\n    private String mMusicFilePath = null;\n    private AssetFileDescriptor mMusicAssetFileDescriptor = null;\n    private boolean mIsRecordCompleted;\n    private boolean mIsMuteMusicPlayer;\n    private boolean mIsMuteMicrophone;\n\n    private String mSectionFileName;\n    private double mVideoTailMs;\n    private long mOutputDurationMs;\n    private long mLastFrameTimeNs = -1;\n    protected volatile double mSectionDurationMs;\n    private static final float DURATION_TOLARENCE = 1.02F;\n\n    private Stack<Double> mSpeedStack = new Stack<>();\n    private Stack<Long> mSectionRecordedDurationStack = new Stack<>();\n\n    private RawFrameExtractor mMusicFrameExtractor;\n    private MediaExtractor mMusicAudioExtractor;\n    private AudioResampler mMusicResampler;\n\n    private volatile long mMusicEncodeFrameTimestampUs;\n    private final Object mAudioRecordTimeBeyondMusicEncodeTime = new Object();\n\n    private long mMusicOutputFrameIntervalUs;\n\n    private Stack<Long> mMusicExtractorStartTimeOfSections;\n    private long mMusicExtractorSeekTimeUs;\n    private int mMusicBeginPosition;\n\n    private volatile boolean mEndSectionMarked;\n\n    public ShortAudioRecorderCore() {\n        Logger.RECORD.i(TAG, \"init\");\n    }\n\n    public void prepare(Context context,\n                        PLMicrophoneSetting microphoneSetting,\n                        PLAudioEncodeSetting audioEncodeSetting,\n                        PLRecordSetting recordSetting) {\n        Logger.RECORD.i(TAG, \"prepare +\");\n\n        ShortVideoCore.init(context);\n        mQosManager = QosManager.getInstance(context);\n        mQosManager.recordFunction(getQosFunctionName());\n\n        mContext = context;\n        mRecordSetting = recordSetting;\n        mMicrophoneSetting = microphoneSetting;\n        mAudioEncodeSetting = audioEncodeSetting;\n\n        mAudioManager = new AudioManager(microphoneSetting);\n        if (audioEncodeSetting.isHWCodecEnabled()) {\n            mAudioEncoder = new HWAudioEncoder(audioEncodeSetting);\n        } else {\n            mAudioEncoder = new SWAudioEncoder(audioEncodeSetting);\n        }\n        mSectionManager = initSectionManager();\n        mSectionManager.setMaxOutputDuration(recordSetting.getMaxRecordDuration());\n        mSectionManager.setOnSectionStateListener(this);\n        mAudioEncoder.setOnEncodeStateChangedListener(mOnAudioEncodeStateChangedListener);\n        mAudioManager.setAudioFrameListener(this);\n\n        int aacFrameSize = 1024;\n        mMusicOutputFrameIntervalUs = (long) (1000000.0 * aacFrameSize / mAudioEncodeSetting.getSamplerate());\n\n        Logger.RECORD.i(TAG, \"prepare -\");\n    }\n\n    public void setRecordSpeed(double recordSpeed) {\n        if (!isFeatureAuthorized(Feature.record_speed)) {\n            return;\n        }\n\n        mQosManager.recordFunction(\"camera_recorder_speed\");\n        if (isEncodersReady()) {\n            Logger.RECORD.w(TAG, \"can't set speed while recording!!!\");\n            return;\n        }\n\n        boolean validSpeed = (recordSpeed > 1 && recordSpeed % 2 == 0) || (recordSpeed < 1 && (1 / recordSpeed) % 2 == 0) || recordSpeed == 1;\n        if (validSpeed) {\n            Logger.RECORD.i(TAG, \"set record speed to: \" + recordSpeed);\n            mRecordSpeed = recordSpeed;\n            mAudioSpeedAdjustor.setSpeed(mRecordSpeed);\n            mSectionManager.setSpeed(mRecordSpeed);\n        } else {\n            Logger.RECORD.w(TAG, \"only support multiple of 2 !!!\");\n        }\n    }\n\n    public void resume() {\n        Logger.RECORD.i(TAG, \"resume +\");\n        if (isSourcesReady()) {\n            Logger.RECORD.w(TAG, \"sources already ready !!!\");\n            return;\n        }\n        if (mSourcesReadying) {\n            Logger.RECORD.w(TAG, \"source readying !!!\");\n            return;\n        }\n\n        mSourcesReadying = true;\n\n        if (!mAudioManager.startRecording()) {\n            if (mRecordStateListener != null) {\n                mRecordStateListener.onError(PLErrorCode.ERROR_SETUP_MICROPHONE_FAILED);\n                mQosManager.recordError(PLErrorCode.ERROR_SETUP_MICROPHONE_FAILED);\n            }\n        }\n        Logger.RECORD.i(TAG, \"resume -\");\n    }\n\n    public void pause() {\n        Logger.RECORD.i(TAG, \"pause +\");\n        endSection();\n        mSourcesReadying = false;\n        mAudioSourceReady = false;\n\n        mAudioFormatReady = false;\n\n        mAudioManager.stopRecording();\n        Logger.RECORD.i(TAG, \"pause -\");\n    }\n\n    public void destroy(boolean clearSections) {\n        Logger.RECORD.i(TAG, \"destroy + clearSections: \" + clearSections);\n        if (clearSections) {\n            mSectionManager.clearSections(false);\n        }\n        Logger.RECORD.i(TAG, \"destroy -\");\n    }\n\n    protected String getQosFunctionName() {\n        return \"audio_recorder\";\n    }\n\n    protected boolean isSourcesReady() {\n        return mAudioSourceReady;\n    }\n\n    protected boolean isEncodersReady() {\n        return mAudioEncoderReady;\n    }\n\n    protected boolean isFormatsReady() {\n        return mAudioFormatReady;\n    }\n\n    protected boolean isFormatsUnReady() {\n        return !mAudioFormatReady;\n    }\n\n    protected SectionManager initSectionManager() {\n        return new SectionManager(mContext, mRecordSetting, mAudioEncodeSetting);\n    }\n\n    protected boolean isFeatureAuthorized(AuthModel.Feature feature) {\n        if (!ZeusManager.getInstance().isFeatureAuthorized(feature)) {\n            if (mRecordStateListener != null) {\n                mRecordStateListener.onError(PLErrorCode.ERROR_UNAUTHORIZED);\n            }\n            if (mQosManager != null) {\n                mQosManager.recordError(PLErrorCode.ERROR_UNAUTHORIZED);\n            }\n            return false;\n        }\n        return true;\n    }\n\n    public synchronized boolean beginSection(String fileName) {\n        Logger.RECORD.i(TAG, \"beginSection +\");\n\n        if (!isFeatureAuthorized(Feature.record_microphone_capture)) {\n            return false;\n        }\n\n        if (!mRecordSetting.IsRecordSpeedVariable() && !mMaxDurationCalibrated) {\n            mRecordSetting.setMaxRecordDuration((long) (mRecordSetting.getMaxRecordDuration() / mRecordSpeed));\n            mMaxDurationCalibrated = true;\n        }\n\n        if (mMusicPlayer != null && !mIsMusicPlayerPrepared) {\n            Logger.RECORD.i(TAG, \"player is not prepared!\");\n            return false;\n        }\n        if (mEncodersReadying || mSectionBegan) {\n            Logger.RECORD.w(TAG, \"section begin ongoing !!!\");\n            return false;\n        }\n        if (mOutputDurationMs >= mRecordSetting.getMaxRecordDuration()) {\n            Logger.RECORD.w(TAG, \"reached the max record duration\");\n            return false;\n        }\n\n        mSectionFileName = fileName;\n        mEncodersReadying = true;\n\n        mAudioSpeedAdjustor.setListener(new AudioSpeedAdjustor.OnAdjustListener() {\n            @Override\n            public void onAdjust(ByteBuffer buf, int size, long pts) {\n                mAudioEncoder.encode(buf, size, pts);\n            }\n        });\n        mAudioEncoder.start();\n        if (mMusicPlayer != null && !mIsRecordCompleted) {\n            mMusicPaths.push(mMusicFilePath == null ? mMusicAssetFileDescriptor : mMusicFilePath);\n            mMusicPlayer.start();\n            mStartTimeOfSections.push(mMusicPlayer.getCurrentPosition());\n            mMusicExtractorStartTimeOfSections.push(mMusicExtractorSeekTimeUs);\n        }\n        Logger.RECORD.i(TAG, \"beginSection -\");\n        return true;\n    }\n\n    public synchronized boolean endSection() {\n        Logger.RECORD.i(TAG, \"endSection +\");\n        if (!mEncodersReadying && !mSectionBegan) {\n            Logger.RECORD.w(TAG, \"not started !!!\");\n            return false;\n        }\n\n        if (mMusicPlayer != null) {\n            mMusicPlayer.pause();\n        }\n\n        if (needDecodeMusic()) {\n            // mark end, and wait music encode time >= section recorded time\n            // if music decode & encode too slow (which is a rare situation)\n            synchronized (mAudioRecordTimeBeyondMusicEncodeTime) {\n                mEndSectionMarked = true;\n                if (isMusicEncodeTimeBeyondAudioRecordTime()) {\n                    // notify to jump out from waiting even if music encode time beyond audio record time\n                    mAudioRecordTimeBeyondMusicEncodeTime.notify();\n                }\n            }\n        } else {\n            stopAudioEncoder();\n        }\n\n        Logger.RECORD.i(TAG, \"endSection -\");\n        return true;\n    }\n\n    private boolean needDecodeMusic() {\n        return mMusicPlayer != null && mIsMuteMicrophone;\n    }\n\n    private void stopAudioEncoder() {\n        mAudioEncoderReady = false;\n        mAudioEncoder.stop();\n    }\n\n    public boolean deleteLastSection() {\n        Logger.RECORD.i(TAG, \"deleteLastSection +\");\n        if (mEncodersReadying || mSectionBegan) {\n            Logger.RECORD.w(TAG, \"cannot delete while working !!!\");\n            return false;\n        }\n        boolean ret = mSectionManager.deleteLastSection();\n        if (mMusicPaths != null && mMusicPaths.empty()) {\n            releaseMusicPlayer();\n        }\n        if (ret && mMusicPlayer != null) {\n            deleteMusicSection(false);\n        }\n        Logger.RECORD.i(TAG, \"deleteLastSection -\");\n        return ret;\n    }\n\n    public boolean deleteAllSections() {\n        Logger.RECORD.i(TAG, \"deleteAllSections +\");\n        if (mEncodersReadying || mSectionBegan) {\n            Logger.RECORD.w(TAG, \"cannot delete sections while working !!!\");\n            return false;\n        }\n        boolean ret = mSectionManager.clearSections(true);\n        if (mMusicPaths != null && mMusicPaths.empty()) {\n            releaseMusicPlayer();\n        }\n        if (ret && mMusicPlayer != null) {\n            deleteMusicSection(true);\n        }\n\n        Logger.RECORD.i(TAG, \"deleteAllSections -\");\n        return ret;\n    }\n\n    private void deleteMusicSection(boolean isAllDelete) {\n        Object musicPath = mMusicPaths.pop();\n        int seekTime = mStartTimeOfSections.pop();\n        long extractorSeekTime = mMusicExtractorStartTimeOfSections.pop();\n\n        if (isAllDelete) {\n            while (mMusicPaths.size() > 0) {\n                musicPath = mMusicPaths.pop();\n            }\n            while (mStartTimeOfSections.size() > 0) {\n                seekTime = mStartTimeOfSections.pop();\n            }\n            while (mMusicExtractorStartTimeOfSections.size() > 0) {\n                extractorSeekTime = mMusicExtractorStartTimeOfSections.pop();\n            }\n        }\n        if (musicPath instanceof String) {\n            if (mMusicFilePath == null || !mMusicFilePath.equals((String) musicPath)) {\n                mMusicFilePath = (String) musicPath;\n                mMusicAssetFileDescriptor = null;\n                configMusicPlayer(musicPath);\n            }\n        } else {\n            if (mMusicAssetFileDescriptor == null || !mMusicAssetFileDescriptor.equals((AssetFileDescriptor) musicPath)) {\n                mMusicAssetFileDescriptor = (AssetFileDescriptor) musicPath;\n                mMusicFilePath = null;\n                configMusicPlayer(musicPath);\n            }\n        }\n        mMusicPlayer.seekTo(seekTime);\n        mIsRecordCompleted = false;\n\n        mMusicExtractorSeekTimeUs = extractorSeekTime;\n    }\n\n    public void concatSections(PLVideoSaveListener listener) {\n        Logger.RECORD.i(TAG, \"concatSections +\");\n\n        if (!ZeusManager.getInstance().isAuthorized()) {\n            Logger.SYSTEM.e(\"unauthorized !\");\n            mQosManager.recordError(PLErrorCode.ERROR_UNAUTHORIZED);\n            if (listener != null) {\n                listener.onSaveVideoFailed(PLErrorCode.ERROR_UNAUTHORIZED);\n            }\n            return;\n        }\n\n        if (mEncodersReadying) {\n            Logger.RECORD.w(TAG, \"cannot concat sections while readying !!!\");\n            mQosManager.recordError(PLErrorCode.ERROR_WRONG_STATUS);\n            if (listener != null) {\n                listener.onSaveVideoFailed(PLErrorCode.ERROR_WRONG_STATUS);\n            }\n            return;\n        }\n\n        if (mSectionBegan) {\n            mConcatSectionsOnStop = true;\n            mVideoSaveListener = listener;\n            endSection();\n        } else {\n            mSectionManager.concatSections(listener);\n        }\n        Logger.RECORD.i(TAG, \"concatSections -\");\n    }\n\n    public void cancelConcat() {\n        Logger.RECORD.i(TAG, \"cancelConcat +\");\n        mSectionManager.cancelConcat();\n        Logger.RECORD.i(TAG, \"cancelConcat -\");\n    }\n\n    public void mute(boolean muted) {\n        if (!isFeatureAuthorized(record_mute)) {\n            return;\n        }\n        Logger.RECORD.i(TAG, \"mute: \" + muted);\n        mIsMuteMicrophone = muted;\n        mAudioManager.mute(muted);\n    }\n\n    public void setMusicFile(String filePath) {\n        if (!isFeatureAuthorized(record_audio_mix)){\n            return;\n        }\n        if (isEncodersReady()) {\n            Logger.RECORD.e(TAG, \"cannot add audio file when recording!\");\n            return;\n        }\n        if (filePath == null) {\n            releaseMusicPlayer();\n            return;\n        }\n\n        mute(true);\n        mMusicFilePath = filePath;\n        mMusicAssetFileDescriptor = null;\n\n        configMusicPlayer(mMusicFilePath);\n    }\n\n    public void setMusicFile(String filePath, boolean isMuteMusicPlayer) {\n        mIsMuteMusicPlayer = isMuteMusicPlayer;\n        setMusicFile(filePath);\n    }\n\n\n    public void setMusicAsset(AssetFileDescriptor afd) {\n        if (!isFeatureAuthorized(record_audio_mix)){\n            return;\n        }\n        if (isEncodersReady()) {\n            Logger.RECORD.e(TAG, \"Cannot add audio file when recording!\");\n            return;\n        }\n        if (afd == null) {\n            releaseMusicPlayer();\n            return;\n        }\n\n        mute(true);\n        mMusicFilePath = null;\n        mMusicAssetFileDescriptor = afd;\n\n        configMusicPlayer(mMusicAssetFileDescriptor);\n    }\n\n    public boolean saveToDraftBox(String tag) {\n        return mSectionManager.saveToDraftBox(tag, null, mMicrophoneSetting, null, mAudioEncodeSetting,\n                null, mRecordSetting);\n    }\n\n    public boolean recoverFromDraft(Context context, Draft draft) {\n        if (draft == null) {\n            Logger.RECORD.e(TAG, \"Error on recoverFromDraft, null draft\");\n            return false;\n        }\n        mRecordSetting = draft.getRecordSetting();\n        mMicrophoneSetting = draft.getMicrophoneSetting();\n        mAudioEncodeSetting = draft.getAudioEncodeSetting();\n\n        prepare(context, mMicrophoneSetting, mAudioEncodeSetting, mRecordSetting);\n\n        mSectionManager = initSectionManager();\n        mSectionManager.setMaxOutputDuration(mRecordSetting.getMaxRecordDuration());\n        mSectionManager.setOnSectionStateListener(this);\n        return mSectionManager.recoverFromDraft(draft);\n    }\n\n    private void configMusicPlayer(Object musicPath) {\n        Logger.RECORD.i(TAG, \"configMusicPlayer...\");\n        if (mMusicPlayer != null) {\n            mMusicPlayer.reset();\n            mIsMusicPlayerPrepared = false;\n        }\n        if (mMusicPlayer == null) {\n            mMusicPlayer = new MediaPlayer();\n            mStartTimeOfSections = new Stack<>();\n            mMusicPaths = new Stack<>();\n            mMusicExtractorStartTimeOfSections = new Stack<>();\n        }\n        try {\n            if (musicPath instanceof String) {\n                mMusicPlayer.setDataSource((String) musicPath);\n            } else {\n                mMusicPlayer.setDataSource(((AssetFileDescriptor) musicPath).getFileDescriptor(), ((AssetFileDescriptor) musicPath).getStartOffset(), ((AssetFileDescriptor) musicPath).getLength());\n            }\n            if (mIsMuteMusicPlayer) {\n                mMusicPlayer.setVolume(0, 0);\n            }\n            mMusicPlayer.prepare();\n            mMusicPlayer.setOnCompletionListener(new MediaPlayer.OnCompletionListener() {\n                @Override\n                public void onCompletion(MediaPlayer mediaPlayer) {\n                    mMusicPlayer.seekTo(mMusicBeginPosition);\n                    mMusicPlayer.start();\n                }\n            });\n            mIsMusicPlayerPrepared = true;\n            mMusicExtractorSeekTimeUs = 0;\n        } catch (IOException e) {\n            Logger.RECORD.e(TAG, e.toString());\n            releaseMusicPlayer();\n            if (mRecordStateListener != null) {\n                mRecordStateListener.onError(PLErrorCode.ERROR_IO_EXCEPTION);\n            }\n        }\n    }\n\n    private void startMusicExtractorInternal() {\n        Logger.RECORD.i(TAG, \"startMusicExtractorInternal + \");\n\n        if (mMusicAssetFileDescriptor != null) {\n            mMusicAudioExtractor = createMediaExtractor(mMusicAssetFileDescriptor);\n        } else {\n            mMusicAudioExtractor = createMediaExtractor(mMusicFilePath);\n        }\n\n        MediaFormat musicAudioFormat = selectAudioTrackAndGetFormat(mMusicAudioExtractor);\n        if (musicAudioFormat == null) {\n            Logger.RECORD.e(TAG, \"start music extractor failed!\");\n            return;\n        }\n\n        mMusicFrameExtractor = new RawFrameExtractor(mMusicAudioExtractor, musicAudioFormat);\n        mMusicFrameExtractor.setLoop(true);\n        mMusicFrameExtractor.setOnFrameAvailableListener(mOnMusicFrameAvailableListener);\n        mMusicFrameExtractor.setOnFormatListener(new RawFrameExtractor.OnOutputFormatListener() {\n            @Override\n            public void onOutputFormat(MediaFormat format) {\n                mMusicResampler = new AudioResampler();\n                mMusicResampler.setResampledFrameListener(mMusicResampledFrameListener);\n                mMusicResampler.init(format.getInteger(MediaFormat.KEY_SAMPLE_RATE), format.getInteger(MediaFormat.KEY_CHANNEL_COUNT), 16,\n                        mAudioEncodeSetting.getSamplerate(), mAudioEncodeSetting.getChannels(), 16);\n            }\n        });\n        mMusicFrameExtractor.start(mMusicExtractorSeekTimeUs);\n\n        Logger.RECORD.i(TAG, \"startMusicExtractorInternal - \");\n    }\n\n    private void releaseMusicExtractor() {\n        if (mMusicFrameExtractor != null) {\n            mMusicFrameExtractor.stop();\n            mMusicFrameExtractor = null;\n        }\n        if (mMusicAudioExtractor != null) {\n            mMusicAudioExtractor.release();\n            mMusicAudioExtractor = null;\n        }\n        if (mMusicResampler != null) {\n            mMusicResampler.release();\n            mMusicResampler = null;\n        }\n    }\n\n    private void releaseMusicPlayer() {\n        if (mMusicPlayer != null) {\n            mMusicPlayer.stop();\n            mMusicPlayer.release();\n        }\n        mMusicPlayer = null;\n        mStartTimeOfSections = null;\n        mMusicPaths = null;\n        mIsMusicPlayerPrepared = false;\n        mIsRecordCompleted = false;\n        mMusicExtractorStartTimeOfSections = null;\n        mMusicBeginPosition = 0;\n    }\n\n    public void setMusicPosition(int position) {\n        if (mMusicPlayer != null) {\n            mMusicBeginPosition = position;\n            mMusicPlayer.seekTo(position);\n            mMusicExtractorSeekTimeUs = position * 1000L;\n        } else {\n            Logger.RECORD.e(TAG, \"setMusicPosition failed, you must set music file firstly!\");\n        }\n    }\n\n    public int getMusicPosition() {\n        if (mMusicPlayer != null) {\n            return mMusicPlayer.getCurrentPosition();\n        }\n        return -1;\n    }\n\n    public final void setAudioFrameListener(PLAudioFrameListener listener) {\n        mAudioFrameListener = listener;\n    }\n\n    public final void setRecordStateListener(PLRecordStateListener listener) {\n        mRecordStateListener = listener;\n    }\n\n    @Override\n    public void onAudioRecordFailed(int errorCode) {\n        if (mAudioFrameListener != null) {\n            mAudioFrameListener.onAudioRecordFailed(errorCode);\n        }\n    }\n\n    @Override\n    public void onAudioFrameAvailable(byte[] data, long timestampNs) {\n        if (mSourcesReadying && !mAudioSourceReady) {\n            mAudioSourceReady = true;\n            callbackReady();\n        }\n\n        if (mAudioFrameListener != null) {\n            mAudioFrameListener.onAudioFrameAvailable(data, timestampNs);\n        }\n\n        if (isEncodersReady()) {\n            if (mVideoTailMs >= mRecordSetting.getMaxRecordDuration() * DURATION_TOLARENCE) {\n                Logger.RECORD.w(TAG, \"reached the max record duration\");\n                endSection();\n                onRecordCompleted();\n                return;\n            }\n\n            if (needDecodeMusic()) {\n                synchronized (mAudioRecordTimeBeyondMusicEncodeTime) {\n                    increaseVideoAndSectionTime(timestampNs);\n                }\n            } else {\n                increaseVideoAndSectionTime(timestampNs);\n            }\n\n            Logger.RECORD.i(TAG, \"mVideoTailMs: \" + mVideoTailMs + \"; END: \" + (mRecordSetting.getMaxRecordDuration() * DURATION_TOLARENCE));\n            mLastFrameTimeNs = timestampNs;\n\n            if (mRecordStateListener != null) {\n                mRecordStateListener.onSectionRecording((long) (mVideoTailMs - mOutputDurationMs), (long) (mVideoTailMs), mSectionRecordedDurationStack.size() + 1);\n            }\n\n            if (!needDecodeMusic()) {\n                ByteBuffer wrap = ByteBuffer.wrap(data);\n                mAudioSpeedAdjustor.adjust(wrap, wrap.remaining(), timestampNs / 1000);\n            } else {\n                // In some situation, the encoder's onEncodedFormatChanged function will callback after encode a few frames.\n                // So we should send a few frames to encoder firstly to make sure onEncodedFormatChanged callback.\n                if (!mAudioFormatReady) {\n                    ByteBuffer silentFrame = ByteBuffer.allocateDirect(data.length);\n                    mAudioEncoder.encode(silentFrame, silentFrame.remaining(), 0);\n                }\n            }\n        }\n\n        if (needDecodeMusic()) {\n            synchronized (mAudioRecordTimeBeyondMusicEncodeTime) {\n                if (!isMusicEncodeTimeBeyondAudioRecordTime()) {\n                    // notify that audio record time has beyond music encode time\n                    mAudioRecordTimeBeyondMusicEncodeTime.notify();\n                }\n            }\n        }\n    }\n\n    private void increaseVideoAndSectionTime(long timestampNs) {\n        if (mLastFrameTimeNs == -1) {\n            mVideoTailMs += (1024 * 1000 / mAudioEncodeSetting.getSamplerate());\n            mSectionDurationMs += (1024 * 1000 / mAudioEncodeSetting.getSamplerate());\n        } else {\n            // We need \"duration / speed\" to convert recording time to output video time.\n            mVideoTailMs += (timestampNs - mLastFrameTimeNs) / mRecordSpeed / 1000000L;\n            mSectionDurationMs += (timestampNs - mLastFrameTimeNs) / mRecordSpeed / 1000000L;\n        }\n    }\n\n    protected synchronized void callbackReady() {\n        if (isSourcesReady()) {\n            mSourcesReadying = false;\n            Logger.RECORD.i(TAG, \"sources are set, we are ready now.\");\n            if (mRecordStateListener != null) {\n                mRecordStateListener.onReady();\n            }\n        }\n    }\n\n    protected synchronized void beginSectionInternal() {\n        if (!mSectionBegan && isFormatsReady()) {\n            Logger.MUXER.i(TAG, \"formats are set, begin section now.\");\n            mSectionManager.beginSection(mSectionFileName);\n            mSectionBegan = true;\n            mEncodersReadying = false;\n            if (mRecordStateListener != null) {\n                mRecordStateListener.onRecordStarted();\n            }\n            if (needDecodeMusic()) {\n                startMusicExtractorInternal();\n            }\n        }\n    }\n\n    protected synchronized void endSectionInternal() {\n        mEncodersReadying = false;\n        if (mSectionBegan && isFormatsUnReady()) {\n            Logger.MUXER.i(TAG, \"formats are unset, end section now.\");\n            mSectionManager.endSection();\n            mSectionBegan = false;\n            if (mRecordStateListener != null) {\n                mRecordStateListener.onRecordStopped();\n            }\n            if (mConcatSectionsOnStop) {\n                mConcatSectionsOnStop = false;\n                mSectionManager.concatSections(mVideoSaveListener);\n            }\n\n            mAudioSpeedAdjustor.reset();\n        }\n    }\n\n    private AudioResampler.ResampledFrameListener mMusicResampledFrameListener = new AudioResampler.ResampledFrameListener() {\n        @Override\n        public void onResampledFrame(ByteBuffer buffer, int size) {\n            mAudioEncoder.encode(buffer, size, mMusicEncodeFrameTimestampUs);\n            mMusicEncodeFrameTimestampUs += mMusicOutputFrameIntervalUs;\n        }\n    };\n\n    private RawFrameExtractor.OnFrameAvailableListener mOnMusicFrameAvailableListener = new RawFrameExtractor.OnFrameAvailableListener() {\n        @Override\n        public void onFrameAvailable(ByteBuffer buffer, int size, long timestampUs, long elapseTimestampUs, boolean eof) {\n            if (!mAudioEncoderReady) {\n                return;\n            }\n\n            synchronized (mAudioRecordTimeBeyondMusicEncodeTime) {\n                mMusicResampler.resample(buffer, buffer.position(), size);\n                mMusicExtractorSeekTimeUs = timestampUs;\n\n                while (isMusicEncodeTimeBeyondAudioRecordTime()) {\n                    // if music decode too slow, then when it catch up\n                    // stop, release and jump\n                    if (tryRelaseMusicStuff()) {\n                        return;\n                    }\n\n                    try {\n                        // music decode too fast, wait for audio record to catch up\n                        mAudioRecordTimeBeyondMusicEncodeTime.wait();\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n\n                    // if user end section explicitly\n                    // then no matter music encode time beyond audio record time or not\n                    // stop, release and jump out\n                    if (tryRelaseMusicStuff()) {\n                        return;\n                    }\n                }\n            }\n\n        }\n\n        private boolean tryRelaseMusicStuff() {\n            if (mEndSectionMarked) {\n                stopAudioEncoder();\n                releaseMusicExtractor();\n                mEndSectionMarked = false;\n                return true;\n            }\n            return false;\n        }\n    };\n\n    private boolean isMusicEncodeTimeBeyondAudioRecordTime() {\n        return mMusicEncodeFrameTimestampUs > mSectionDurationMs * 1000;\n    }\n\n    protected HWEncoderBase.OnEncodeStateChangedListener mOnAudioEncodeStateChangedListener = new HWEncoderBase.OnEncodeStateChangedListener() {\n        @Override\n        public void onEncodeStarted(boolean isSuccess) {\n            Logger.ENCODE.i(TAG, \"audio encoder started: \" + isSuccess);\n            mAudioEncoderReady = isSuccess;\n            if (!isSuccess && mRecordStateListener != null) {\n                mEncodersReadying = false;\n                mRecordStateListener.onError(PLErrorCode.ERROR_SETUP_AUDIO_ENCODER_FAILED);\n                mQosManager.recordError(PLErrorCode.ERROR_SETUP_AUDIO_ENCODER_FAILED);\n            }\n        }\n\n        @Override\n        public void onEncodeStopped(boolean isExceptionalStop) {\n            Logger.ENCODE.i(TAG, \"audio encoder stopped.\");\n            mAudioEncoderReady = false;\n            mAudioFormatReady = false;\n            mLastFrameTimeNs = -1;\n            mSectionDurationMs = 0;\n            mMusicEncodeFrameTimestampUs = 0;\n            endSectionInternal();\n        }\n\n        @Override\n        public void onSurfaceCreated(Surface surface) {\n\n        }\n\n        @Override\n        public void onEncodedFormatChanged(MediaFormat format) {\n            Logger.MUXER.i(TAG, \"got audio format:\" + format.toString());\n            mSectionManager.setAudioFormat(format);\n            mAudioFormatReady = true;\n            beginSectionInternal();\n        }\n\n        @Override\n        public void onEncodedFrameAvailable(ByteBuffer buffer, MediaCodec.BufferInfo info) {\n            if (mSectionBegan) {\n                Logger.ENCODE.d(TAG, \"audio encoded frame size:\" + info.size + \" ts:\" + info.presentationTimeUs);\n                mSectionManager.writeAudio(buffer, info);\n            }\n        }\n    };\n\n    @Override\n    public void onNoDataWritten() {\n        if (mRecordStateListener != null) {\n            mRecordStateListener.onDurationTooShort();\n        }\n    }\n\n    @Override\n    public void onSectionIncreased(long incDurationMs, long totalDurationMs, int sectionCount) {\n        long totalRecordedDuration = (long) (totalDurationMs - incDurationMs + incDurationMs * mRecordSpeed);\n        mSpeedStack.push(new Double(mRecordSpeed));\n        mSectionRecordedDurationStack.push(new Long(totalRecordedDuration));\n        mOutputDurationMs += incDurationMs;\n        Logger.RECORD.i(TAG, \"Section increased speed: \" + mRecordSpeed + \"; Section count\" + sectionCount + \"; Total duration: \" + totalDurationMs + \"; Section duration: \" + incDurationMs + \"; Recording duration: \" + totalRecordedDuration);\n        if (mRecordStateListener != null) {\n            mRecordStateListener.onSectionIncreased((long) (incDurationMs * mRecordSpeed), totalRecordedDuration, sectionCount);\n        }\n    }\n\n    @Override\n    public void onSectionDecreased(long decDurationMs, long totalDurationMs, int sectionCount) {\n        if (sectionCount == 0 && (!mRecordSetting.IsRecordSpeedVariable())) {\n            mMaxDurationCalibrated = false;\n            mRecordSetting.setMaxRecordDuration((long) (mRecordSetting.getMaxRecordDuration() * mRecordSpeed));\n        }\n        while (mSectionRecordedDurationStack.size() > sectionCount) {\n            mSectionRecordedDurationStack.pop();\n        }\n        mOutputDurationMs -= decDurationMs;\n        mVideoTailMs = mOutputDurationMs;\n        double sectionSpeed = mSpeedStack.isEmpty() ? 0 : mSpeedStack.pop().doubleValue();\n        long totalRecordedDuration = mSectionRecordedDurationStack.isEmpty() ? 0 : mSectionRecordedDurationStack.pop().longValue();\n        Logger.RECORD.i(TAG, \"Section decreased speed: \" + sectionSpeed + \"; Section count\" + sectionCount + \"RecDurationStackSz: \" + mSectionRecordedDurationStack.size() + \"; Total duration: \" + totalDurationMs + \"; Section duration: \" + decDurationMs + \"; Recording duration: \" + totalRecordedDuration);\n        if (mRecordStateListener != null) {\n            mRecordStateListener.onSectionDecreased((long) (decDurationMs * sectionSpeed), totalRecordedDuration, sectionCount);\n        }\n    }\n\n    public void onRecordCompleted() {\n        mVideoTailMs = 0;\n        if (mRecordStateListener != null) {\n            mRecordStateListener.onRecordCompleted();\n        }\n        if (mMusicPlayer != null) {\n            mMusicPlayer.pause();\n            mIsRecordCompleted = true;\n        }\n    }\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- ../PLDroidShortVideo/library/src/main/java/com/qiniu/pili/droid/shortvideo/core/ShortAudioRecorderCore.java	(date 1564645694000)
+++ ../PLDroidShortVideo/library/src/main/java/com/qiniu/pili/droid/shortvideo/core/ShortAudioRecorderCore.java	(date 1564644314000)
@@ -6,6 +6,7 @@
 import android.media.MediaExtractor;
 import android.media.MediaFormat;
 import android.media.MediaPlayer;
+import android.util.Log;
 import android.view.Surface;
 
 import com.qiniu.pili.droid.shortvideo.PLAudioEncodeSetting;
@@ -29,6 +30,7 @@
 import java.nio.ByteBuffer;
 import java.util.Stack;
 
+import static com.qiniu.pili.droid.shortvideo.core.AuthModel.Feature.edit_audio_mix;
 import static com.qiniu.pili.droid.shortvideo.core.AuthModel.Feature.record_audio_mix;
 import static com.qiniu.pili.droid.shortvideo.core.AuthModel.Feature.record_mute;
 import static com.qiniu.pili.droid.shortvideo.utils.MediaUtils.createMediaExtractor;
@@ -87,10 +89,10 @@
 
     private String mSectionFileName;
     private double mVideoTailMs;
+    private double mVideoTotalTimeMs;
     private long mOutputDurationMs;
     private long mLastFrameTimeNs = -1;
     protected volatile double mSectionDurationMs;
-    private static final float DURATION_TOLARENCE = 1.02F;
 
     private Stack<Double> mSpeedStack = new Stack<>();
     private Stack<Long> mSectionRecordedDurationStack = new Stack<>();
@@ -660,7 +662,7 @@
         }
 
         if (isEncodersReady()) {
-            if (mVideoTailMs >= mRecordSetting.getMaxRecordDuration() * DURATION_TOLARENCE) {
+            if (mVideoTailMs >= mRecordSetting.getMaxRecordDuration()) {
                 Logger.RECORD.w(TAG, "reached the max record duration");
                 endSection();
                 onRecordCompleted();
@@ -675,7 +677,7 @@
                 increaseVideoAndSectionTime(timestampNs);
             }
 
-            Logger.RECORD.i(TAG, "mVideoTailMs: " + mVideoTailMs + "; END: " + (mRecordSetting.getMaxRecordDuration() * DURATION_TOLARENCE));
+            Logger.RECORD.i(TAG, "mVideoTailMs: " + mVideoTailMs + "; END: " + mRecordSetting.getMaxRecordDuration());
             mLastFrameTimeNs = timestampNs;
 
             if (mRecordStateListener != null) {
@@ -708,10 +710,12 @@
     private void increaseVideoAndSectionTime(long timestampNs) {
         if (mLastFrameTimeNs == -1) {
             mVideoTailMs += (1024 * 1000 / mAudioEncodeSetting.getSamplerate());
+            mVideoTotalTimeMs=mVideoTailMs;
             mSectionDurationMs += (1024 * 1000 / mAudioEncodeSetting.getSamplerate());
         } else {
             // We need "duration / speed" to convert recording time to output video time.
             mVideoTailMs += (timestampNs - mLastFrameTimeNs) / mRecordSpeed / 1000000L;
+            mVideoTotalTimeMs=mVideoTailMs;
             mSectionDurationMs += (timestampNs - mLastFrameTimeNs) / mRecordSpeed / 1000000L;
         }
     }
@@ -872,13 +876,26 @@
 
     @Override
     public void onSectionIncreased(long incDurationMs, long totalDurationMs, int sectionCount) {
+        //飞
+        incDurationMs=(long) (mVideoTailMs - mOutputDurationMs);
+        totalDurationMs=(long) mVideoTailMs;
+        sectionCount=mSectionRecordedDurationStack.size() + 1;
+
         long totalRecordedDuration = (long) (totalDurationMs - incDurationMs + incDurationMs * mRecordSpeed);
         mSpeedStack.push(new Double(mRecordSpeed));
         mSectionRecordedDurationStack.push(new Long(totalRecordedDuration));
-        mOutputDurationMs += incDurationMs;
         Logger.RECORD.i(TAG, "Section increased speed: " + mRecordSpeed + "; Section count" + sectionCount + "; Total duration: " + totalDurationMs + "; Section duration: " + incDurationMs + "; Recording duration: " + totalRecordedDuration);
+        //飞
         if (mRecordStateListener != null) {
-            mRecordStateListener.onSectionIncreased((long) (incDurationMs * mRecordSpeed), totalRecordedDuration, sectionCount);
+            if (mVideoTailMs==0){
+                mOutputDurationMs=mRecordSetting.getMaxRecordDuration();
+                mRecordStateListener.onSectionIncreased((long) (mRecordSetting.getMaxRecordDuration()-mOutputDurationMs), mRecordSetting.getMaxRecordDuration(), sectionCount);
+            }else {
+                mOutputDurationMs += incDurationMs;
+                mRecordStateListener.onSectionIncreased((long) (incDurationMs * mRecordSpeed), (long)mVideoTailMs, sectionCount);
+            }
+//            mRecordStateListener.onSectionIncreased((long) (incDurationMs * mRecordSpeed), (long) (mVideoTotalTimeMs), mSectionRecordedDurationStack.size() + 1);
+
         }
     }
 
@@ -893,6 +910,7 @@
         }
         mOutputDurationMs -= decDurationMs;
         mVideoTailMs = mOutputDurationMs;
+        mVideoTotalTimeMs=mVideoTailMs;
         double sectionSpeed = mSpeedStack.isEmpty() ? 0 : mSpeedStack.pop().doubleValue();
         long totalRecordedDuration = mSectionRecordedDurationStack.isEmpty() ? 0 : mSectionRecordedDurationStack.pop().longValue();
         Logger.RECORD.i(TAG, "Section decreased speed: " + sectionSpeed + "; Section count" + sectionCount + "RecDurationStackSz: " + mSectionRecordedDurationStack.size() + "; Total duration: " + totalDurationMs + "; Section duration: " + decDurationMs + "; Recording duration: " + totalRecordedDuration);
